{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiments on the use of the different estimated distributions in the 2D case with toy data, for classification purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T12:40:49.928163Z",
     "start_time": "2021-04-09T12:40:49.889528Z"
    },
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "run init.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "#### Dataset Dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetGenerator(dataset_name=dataset_name, \n",
    "                                            num_samples=num_samples, \n",
    "                                            imbalance_ratio=imbalance_ratio, \n",
    "                                            missing_data_handling=missing_data_handling,\n",
    "                                            imputation_method=imputation_method,\n",
    "                                            verbosity=verbosity)\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.60952648, -0.72029916],\n",
       "        [ 1.03056358,  1.6777475 ],\n",
       "        [-1.31510581,  1.1735564 ],\n",
       "        ...,\n",
       "        [-0.38177019,  0.98798329],\n",
       "        [ 0.64550682, -2.13086448],\n",
       "        [ 1.59439813, -1.65256827]]),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self=dataset\n",
    "self.dataset_name='blobs'\n",
    "num_samples_gt = 2000\n",
    "\n",
    "################################\n",
    "# Generate the positive examples\n",
    "################################\n",
    "if self.dataset_name=='moons':\n",
    "\n",
    "    found=False\n",
    "    while not found:\n",
    "\n",
    "        X_all, labels = datasets.make_moons(n_samples=int(2*self.imbalance_ratio*(self.num_samples+num_samples_gt)), noise=.15, random_state=self.random_state)\n",
    "\n",
    "        idx_out = np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()\n",
    "\n",
    "        X_all[idx_out], labels[idx_out] = datasets.make_moons(n_samples=len(idx_out), noise=.15)\n",
    "\n",
    "        if len(np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()) == 0:\n",
    "            found=True\n",
    "\n",
    "\n",
    "elif self.dataset_name=='circles':\n",
    "\n",
    "    found=False\n",
    "    while not found:\n",
    "        X_all, labels = datasets.make_circles(n_samples=int(2*self.imbalance_ratio*(self.num_samples+num_samples_gt)), factor=.5, noise=.15, random_state=self.random_state)\n",
    "\n",
    "        idx_out = np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()\n",
    "\n",
    "        X_all[idx_out], labels[idx_out] = datasets.make_circles(n_samples=len(idx_out), factor=.5, noise=.15, random_state=self.random_state)\n",
    "\n",
    "        if len(np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()) == 0:\n",
    "            found=True\n",
    "\n",
    "\n",
    "elif self.dataset_name=='blobs':\n",
    "\n",
    "    found=False\n",
    "    while not found:\n",
    "\n",
    "        X_all, labels = datasets.make_blobs(n_samples=int(2*self.imbalance_ratio*(self.num_samples+num_samples_gt)), centers=[[-1, 0],[1, 0]], cluster_std=.3, random_state=self.random_state)\n",
    "\n",
    "        idx_out = np.argwhere( (X_all[:,0]>2.4) | (X_all[:,0] < -2.4) | (X_all[:,1]>2.4) | (X_all[:,1] < -2.4) ).squeeze()\n",
    "\n",
    "        X_all[idx_out], labels[idx_out] = datasets.make_blobs(n_samples=len(idx_out), centers=[[-1, 0],[1, 0]],\n",
    "                                                                cluster_std=.05)\n",
    "\n",
    "        if len(np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()) == 0:\n",
    "            found=True\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Please use 'moons', 'circles', or 'blobs' datasets.\")             \n",
    "\n",
    "# normalize dataset for easier parameter selection\n",
    "X_all = StandardScaler().fit_transform(X_all)\n",
    "\n",
    "# Select the positive examples\n",
    "X_all = X_all[np.argwhere(labels==1).squeeze()]\n",
    "\n",
    "# Separate ground truth and training data\n",
    "X_pos = X_all[:int(self.num_samples*self.imbalance_ratio),:]\n",
    "#Xgt_pos = X_all[int(num_samples*imbalance_ratio):,:]\n",
    "labels_pos = 1*np.ones((X_pos.shape[0], 1))\n",
    "\n",
    "#labelsgt_pos  = 1*np.ones((Xgt_pos.shape[0], 1))\n",
    "\n",
    "################################\n",
    "# Generate the negative examples\n",
    "################################\n",
    "if self.dataset_name=='moons':\n",
    "\n",
    "    found=False\n",
    "    while not found:\n",
    "\n",
    "        X_all, labels = datasets.make_moons(n_samples=int(2*(1-self.imbalance_ratio)*(self.num_samples+num_samples_gt)), noise=.15, random_state=self.random_state)\n",
    "        idx_out = np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()\n",
    "\n",
    "        X_all[idx_out], labels[idx_out] = datasets.make_moons(n_samples=len(idx_out), noise=.15)\n",
    "\n",
    "        if len(np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()) == 0:\n",
    "            found=True\n",
    "\n",
    "elif self.dataset_name=='circles':\n",
    "\n",
    "    found=False\n",
    "    while not found:\n",
    "\n",
    "        X_all, labels = datasets.make_circles(n_samples=int(2*(1-self.imbalance_ratio)*(self.num_samples+num_samples_gt)), factor=.5, noise=.15, random_state=self.random_state)\n",
    "\n",
    "        idx_out = np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()\n",
    "\n",
    "        X_all[idx_out], labels[idx_out] = datasets.make_circles(n_samples=len(idx_out), factor=.5, noise=.15, random_state=self.random_state)\n",
    "\n",
    "        if len(np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()) == 0:\n",
    "            found=True\n",
    "\n",
    "\n",
    "\n",
    "elif self.dataset_name=='blobs':\n",
    "\n",
    "    found=False\n",
    "    while not found:\n",
    "\n",
    "        X_all, labels = datasets.make_blobs(n_samples=int(2*(1-self.imbalance_ratio)*(self.num_samples+num_samples_gt)), centers=[[-1, 0],[1, 0]], cluster_std=.3, random_state=self.random_state)\n",
    "\n",
    "        idx_out = np.argwhere( (X_all[:,0]>2.4) | (X_all[:,0] < -2.4) | (X_all[:,1]>2.4) | (X_all[:,1] < -2.4) ).squeeze()\n",
    "\n",
    "        X_all[idx_out], labels[idx_out] = datasets.make_blobs(n_samples=len(idx_out), centers=[[-1, 0],[1, 0]],\n",
    "                                                                cluster_std=.05, random_state=self.random_state)\n",
    "\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Please use 'moons', 'circles', or 'blobs' datasets.\")               \n",
    "\n",
    "# normalize dataset for easier parameter selection\n",
    "X_all = StandardScaler().fit_transform(X_all)\n",
    "\n",
    "# Select the negative examples\n",
    "X_all = X_all[np.argwhere(labels==0).squeeze()]\n",
    "\n",
    "# Separate ground truth and training data\n",
    "X_neg = X_all[:int(self.num_samples*(1-self.imbalance_ratio)),:] \n",
    "#Xgt_neg = X_all[int(num_samples*(1-imbalance_ratio)):,:]\n",
    "labels_neg = np.zeros((X_neg.shape[0], 1))\n",
    "#labelsgt_neg = np.zeros((Xgt_neg.shape[0], 1))\n",
    "\n",
    "# Combine the positive and negative samples\n",
    "X, y = np.concatenate([X_neg, X_pos], axis=0), np.concatenate([labels_neg, labels_pos], axis=0)\n",
    "#X_gt, y_gt = np.concatenate([Xgt_neg, Xgt_pos], axis=0), np.concatenate([labelsgt_neg, labelsgt_pos], axis=0)\n",
    "\n",
    "# Shuffle the data \n",
    "X_raw, y = shuffle(X, y, random_state=self.random_state)\n",
    "#self.X_gt, self.y_gt = shuffle(X_gt, y_gt, random_state=random_state)\n",
    "\n",
    "X_raw, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    }
   ],
   "source": [
    "\n",
    "found=False\n",
    "while not found:\n",
    "    print('y')\n",
    "\n",
    "    X_all, labels = datasets.make_blobs(n_samples=int(2*self.imbalance_ratio*(self.num_samples+num_samples_gt)), centers=[[-1, 0],[1, 0]], cluster_std=.3, random_state=self.random_state)\n",
    "\n",
    "    idx_out = np.argwhere( (X_all[:,0]>2.4) | (X_all[:,0] < -2.4) | (X_all[:,1]>2.4) | (X_all[:,1] < -2.4) ).squeeze()\n",
    "\n",
    "    X_all[idx_out], labels[idx_out] = datasets.make_blobs(n_samples=len(idx_out), centers=[[-1, 0],[1, 0]],\n",
    "                                                            cluster_std=.05)\n",
    "\n",
    "    if len(np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()) == 0:\n",
    "        found=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model = model.fit(dataset.X_train, dataset.y_train)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "combinations",
   "language": "python",
   "name": "combinations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "321.771px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
