{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment on the encoding and imputing technics for the Nam network, with and without Z ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T12:40:49.928163Z",
     "start_time": "2021-04-09T12:40:49.889528Z"
    },
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "run init.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`NAN` Second set of experiments deciding wheether `using indicator variable is useful`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Parameters of the experiment \"\"\"\n",
    "approach = 'nam'\n",
    "\n",
    "range_dataset_name = ['blobs', 'circles', 'moons']\n",
    "range_ratio_of_missing_values = [0., 0.1, 0.2, 0.3]\n",
    "range_ratio_missing_per_class = [[0,0.25], [0.1, 0.3]]\n",
    "range_imbalance_ratio = [0.1, 0.25, 0.5]\n",
    "range_missingness_pattern = [1, 3, 4, 5]\n",
    "\n",
    "missing_data_handling = 'encoding'#, TODECIDE] #TODO THIS IS WHERE WE SHOULD DO IMUTING BASED ON THE  OTHER EXPERIMENT\n",
    "imputation_method = 'without'\n",
    "range_use_missing_indicator_variables = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blobs - imputation method: encoding missing_data_handling: without imbalance: 0.1 pattern: 1 ratio_missing:0.0 ratio_per_class: None\n",
      "Doing experiment 4!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  Fix parameters \"\"\"\n",
    "#Dataset default parameters\n",
    "num_samples = NUM_SAMPLES\n",
    "\n",
    "# pdf estimation default parameters\n",
    "resolution = RESOLUTION\n",
    "bandwidth = BANDWIDTH\n",
    "\n",
    "# Classification default parameters\n",
    "proportion_train = PROPORTION_TRAIN\n",
    "\n",
    "# Verbosity\n",
    "verbosity=0\n",
    "\n",
    "save=True\n",
    "\n",
    "missingness_dictionnary = {1: (range_ratio_of_missing_values, len(range_ratio_of_missing_values)*[None]),\n",
    "                           2: (range_ratio_of_missing_values, len(range_ratio_of_missing_values)*[None]),\n",
    "                           3: (range_ratio_of_missing_values, len(range_ratio_of_missing_values)*[None]),\n",
    "                           4: (len(range_ratio_missing_per_class)*[None], range_ratio_missing_per_class),\n",
    "                           5: (len(range_ratio_missing_per_class)*[None], range_ratio_missing_per_class)}\n",
    "\n",
    "for dataset_name in range_dataset_name:\n",
    "    \n",
    "    for imbalance_ratio in range_imbalance_ratio:\n",
    "        \n",
    "        for use_missing_indicator_variables in range_use_missing_indicator_variables:\n",
    "\n",
    "            for missingness_pattern, (ratio_of_missing_values_list, ratio_missing_per_class_list) in missingness_dictionnary.items():\n",
    "\n",
    "                for ratio_of_missing_values, ratio_missing_per_class in zip(ratio_of_missing_values_list, ratio_missing_per_class_list):\n",
    "\n",
    "\n",
    "                    if False and check_experiment_already_done(df, \n",
    "                                                      dataset_name=dataset_name, \n",
    "                                                      imbalance_ratio=imbalance_ratio, \n",
    "                                                      missingness_pattern=missingness_pattern, \n",
    "                                                      imputation_method=imputation_method,\n",
    "                                                      use_missing_indicator_variables=use_missing_indicator_variables,\n",
    "                                                      ratio_of_missing_values=ratio_of_missing_values, \n",
    "                                                      ratio_missing_per_class=ratio_missing_per_class):\n",
    "\n",
    "\n",
    "                        print(\"Experiment already done.\")\n",
    "                        continue\n",
    "\n",
    "                    print(\"{} - imputation method: {} missing_data_handling: {} imbalance: {} pattern: {} ratio_missing:{} ratio_per_class: {}\".format(dataset_name, \n",
    "                                                                                                                                                        missing_data_handling,\n",
    "                                                                                                                                                          imputation_method, \n",
    "                                                                                                                                                          imbalance_ratio,\n",
    "                                                                                                                                                          missingness_pattern,\n",
    "                                                                                                                                                          ratio_of_missing_values, \n",
    "                                                                                                                                                          ratio_missing_per_class))\n",
    "\n",
    "                    try:\n",
    "                        start_time = time()\n",
    "\n",
    "                        dataset = DatasetGenerator(dataset_name=dataset_name, \n",
    "                                                num_samples=num_samples, \n",
    "                                                imbalance_ratio=imbalance_ratio, \n",
    "                                                missing_data_handling=missing_data_handling,\n",
    "                                                imputation_method=imputation_method,\n",
    "                                                verbosity=verbosity)\n",
    "\n",
    "                        # Creation of the missingness\n",
    "                        dataset.generate_missing_coordinates(missingness_pattern=missingness_pattern, \n",
    "                                                             ratio_of_missing_values=ratio_of_missing_values, \n",
    "                                                             ratio_missing_per_class=ratio_missing_per_class)\n",
    "\n",
    "                        dataset.split_test_train()\n",
    "\n",
    "                        # Create the experiments\n",
    "                        exp = Experiments(dataset_name, \n",
    "                                          dataset=dataset, \n",
    "                                          purpose='classification', \n",
    "                                          approach = approach, \n",
    "                                          previous_experiment=None, \n",
    "                                          save_experiment=save, \n",
    "                                          verbosity=verbosity, \n",
    "                                          debug=False, \n",
    "                                          proportion_train=PROPORTION_TRAIN, \n",
    "                                          resolution=RESOLUTION, \n",
    "                                          bandwidth=BANDWIDTH,\n",
    "                                          random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "                        # Estimate the distributions \n",
    "                        exp.fit()\n",
    "\n",
    "                        # Estimate the distributions \n",
    "                        exp.predict()\n",
    "\n",
    "                        # Plot results\n",
    "                        #exp.plot()\n",
    "\n",
    "\n",
    "                        end_time = time()\n",
    "\n",
    "                        hours, rest = divmod(end_time - start_time, 3600)\n",
    "                        minutes, seconds = divmod(rest, 60)\n",
    "                        print(\"Done ({}h {}m and {:.2f}s).\\n\".format(int(hours), int(minutes), seconds))\n",
    "                    except:\n",
    "                        print(\"/!\\. Error!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetGenerator(dataset_name=dataset_name, \n",
    "                                            num_samples=num_samples, \n",
    "                                            imbalance_ratio=imbalance_ratio, \n",
    "                                            missing_data_handling=missing_data_handling,\n",
    "                                            imputation_method=imputation_method,\n",
    "                                            verbosity=verbosity)\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.60952648, -0.72029916],\n",
       "        [ 1.03056358,  1.6777475 ],\n",
       "        [-1.31510581,  1.1735564 ],\n",
       "        ...,\n",
       "        [-0.38177019,  0.98798329],\n",
       "        [ 0.64550682, -2.13086448],\n",
       "        [ 1.59439813, -1.65256827]]),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self=dataset\n",
    "self.dataset_name='blobs'\n",
    "num_samples_gt = 2000\n",
    "\n",
    "################################\n",
    "# Generate the positive examples\n",
    "################################\n",
    "if self.dataset_name=='moons':\n",
    "\n",
    "    found=False\n",
    "    while not found:\n",
    "\n",
    "        X_all, labels = datasets.make_moons(n_samples=int(2*self.imbalance_ratio*(self.num_samples+num_samples_gt)), noise=.15, random_state=self.random_state)\n",
    "\n",
    "        idx_out = np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()\n",
    "\n",
    "        X_all[idx_out], labels[idx_out] = datasets.make_moons(n_samples=len(idx_out), noise=.15)\n",
    "\n",
    "        if len(np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()) == 0:\n",
    "            found=True\n",
    "\n",
    "\n",
    "elif self.dataset_name=='circles':\n",
    "\n",
    "    found=False\n",
    "    while not found:\n",
    "        X_all, labels = datasets.make_circles(n_samples=int(2*self.imbalance_ratio*(self.num_samples+num_samples_gt)), factor=.5, noise=.15, random_state=self.random_state)\n",
    "\n",
    "        idx_out = np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()\n",
    "\n",
    "        X_all[idx_out], labels[idx_out] = datasets.make_circles(n_samples=len(idx_out), factor=.5, noise=.15, random_state=self.random_state)\n",
    "\n",
    "        if len(np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()) == 0:\n",
    "            found=True\n",
    "\n",
    "\n",
    "elif self.dataset_name=='blobs':\n",
    "\n",
    "    found=False\n",
    "    while not found:\n",
    "\n",
    "        X_all, labels = datasets.make_blobs(n_samples=int(2*self.imbalance_ratio*(self.num_samples+num_samples_gt)), centers=[[-1, 0],[1, 0]], cluster_std=.3, random_state=self.random_state)\n",
    "\n",
    "        idx_out = np.argwhere( (X_all[:,0]>2.4) | (X_all[:,0] < -2.4) | (X_all[:,1]>2.4) | (X_all[:,1] < -2.4) ).squeeze()\n",
    "\n",
    "        X_all[idx_out], labels[idx_out] = datasets.make_blobs(n_samples=len(idx_out), centers=[[-1, 0],[1, 0]],\n",
    "                                                                cluster_std=.05)\n",
    "\n",
    "        if len(np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()) == 0:\n",
    "            found=True\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Please use 'moons', 'circles', or 'blobs' datasets.\")             \n",
    "\n",
    "# normalize dataset for easier parameter selection\n",
    "X_all = StandardScaler().fit_transform(X_all)\n",
    "\n",
    "# Select the positive examples\n",
    "X_all = X_all[np.argwhere(labels==1).squeeze()]\n",
    "\n",
    "# Separate ground truth and training data\n",
    "X_pos = X_all[:int(self.num_samples*self.imbalance_ratio),:]\n",
    "#Xgt_pos = X_all[int(num_samples*imbalance_ratio):,:]\n",
    "labels_pos = 1*np.ones((X_pos.shape[0], 1))\n",
    "\n",
    "#labelsgt_pos  = 1*np.ones((Xgt_pos.shape[0], 1))\n",
    "\n",
    "################################\n",
    "# Generate the negative examples\n",
    "################################\n",
    "if self.dataset_name=='moons':\n",
    "\n",
    "    found=False\n",
    "    while not found:\n",
    "\n",
    "        X_all, labels = datasets.make_moons(n_samples=int(2*(1-self.imbalance_ratio)*(self.num_samples+num_samples_gt)), noise=.15, random_state=self.random_state)\n",
    "        idx_out = np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()\n",
    "\n",
    "        X_all[idx_out], labels[idx_out] = datasets.make_moons(n_samples=len(idx_out), noise=.15)\n",
    "\n",
    "        if len(np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()) == 0:\n",
    "            found=True\n",
    "\n",
    "elif self.dataset_name=='circles':\n",
    "\n",
    "    found=False\n",
    "    while not found:\n",
    "\n",
    "        X_all, labels = datasets.make_circles(n_samples=int(2*(1-self.imbalance_ratio)*(self.num_samples+num_samples_gt)), factor=.5, noise=.15, random_state=self.random_state)\n",
    "\n",
    "        idx_out = np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()\n",
    "\n",
    "        X_all[idx_out], labels[idx_out] = datasets.make_circles(n_samples=len(idx_out), factor=.5, noise=.15, random_state=self.random_state)\n",
    "\n",
    "        if len(np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()) == 0:\n",
    "            found=True\n",
    "\n",
    "\n",
    "\n",
    "elif self.dataset_name=='blobs':\n",
    "\n",
    "    found=False\n",
    "    while not found:\n",
    "\n",
    "        X_all, labels = datasets.make_blobs(n_samples=int(2*(1-self.imbalance_ratio)*(self.num_samples+num_samples_gt)), centers=[[-1, 0],[1, 0]], cluster_std=.3, random_state=self.random_state)\n",
    "\n",
    "        idx_out = np.argwhere( (X_all[:,0]>2.4) | (X_all[:,0] < -2.4) | (X_all[:,1]>2.4) | (X_all[:,1] < -2.4) ).squeeze()\n",
    "\n",
    "        X_all[idx_out], labels[idx_out] = datasets.make_blobs(n_samples=len(idx_out), centers=[[-1, 0],[1, 0]],\n",
    "                                                                cluster_std=.05, random_state=self.random_state)\n",
    "\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Please use 'moons', 'circles', or 'blobs' datasets.\")               \n",
    "\n",
    "# normalize dataset for easier parameter selection\n",
    "X_all = StandardScaler().fit_transform(X_all)\n",
    "\n",
    "# Select the negative examples\n",
    "X_all = X_all[np.argwhere(labels==0).squeeze()]\n",
    "\n",
    "# Separate ground truth and training data\n",
    "X_neg = X_all[:int(self.num_samples*(1-self.imbalance_ratio)),:] \n",
    "#Xgt_neg = X_all[int(num_samples*(1-imbalance_ratio)):,:]\n",
    "labels_neg = np.zeros((X_neg.shape[0], 1))\n",
    "#labelsgt_neg = np.zeros((Xgt_neg.shape[0], 1))\n",
    "\n",
    "# Combine the positive and negative samples\n",
    "X, y = np.concatenate([X_neg, X_pos], axis=0), np.concatenate([labels_neg, labels_pos], axis=0)\n",
    "#X_gt, y_gt = np.concatenate([Xgt_neg, Xgt_pos], axis=0), np.concatenate([labelsgt_neg, labelsgt_pos], axis=0)\n",
    "\n",
    "# Shuffle the data \n",
    "X_raw, y = shuffle(X, y, random_state=self.random_state)\n",
    "#self.X_gt, self.y_gt = shuffle(X_gt, y_gt, random_state=random_state)\n",
    "\n",
    "X_raw, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    }
   ],
   "source": [
    "\n",
    "found=False\n",
    "while not found:\n",
    "    print('y')\n",
    "\n",
    "    X_all, labels = datasets.make_blobs(n_samples=int(2*self.imbalance_ratio*(self.num_samples+num_samples_gt)), centers=[[-1, 0],[1, 0]], cluster_std=.3, random_state=self.random_state)\n",
    "\n",
    "    idx_out = np.argwhere( (X_all[:,0]>2.4) | (X_all[:,0] < -2.4) | (X_all[:,1]>2.4) | (X_all[:,1] < -2.4) ).squeeze()\n",
    "\n",
    "    X_all[idx_out], labels[idx_out] = datasets.make_blobs(n_samples=len(idx_out), centers=[[-1, 0],[1, 0]],\n",
    "                                                            cluster_std=.05)\n",
    "\n",
    "    if len(np.argwhere( (X_all[:,0]>2.49) | (X_all[:,0] < -2.49) | (X_all[:,1]>2.49) | (X_all[:,1] < -2.49) ).squeeze()) == 0:\n",
    "        found=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "combinations",
   "language": "python",
   "name": "combinations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "321.771px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
