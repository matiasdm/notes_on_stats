

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Introduction to Bayesian Inference &#8212; Notes on stats</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-dropdown.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Estimation of PDF and CDF distributions" href="pdfestimation.html" />
    <link rel="prev" title="Notes on statistical analysis and inference" href="../index.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Notes on stats</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Introduction to Bayesian Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pdfestimation.html">
   Estimation of PDF and CDF distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hypothesisTesting.html">
   Hypothesis testing and effect size
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/sections/bayes.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/sections/bayes.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/executablebooks/jupyter-book/blob/master/sections/bayes.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-screening-for-autism-spectrum-disorder">
   Example: Screening for Autism Spectrum Disorder
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#identifying-and-assessing-descriptive-features">
   Identifying and assessing descriptive features.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-importance-of-priors-on-imbalance-problems">
   The importance of priors on imbalance problems
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#posterior-odds">
   Posterior odds
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#performance-measures-for-imbalance-problems">
   Performance measures for imbalance problems
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="introduction-to-bayesian-inference">
<span id="sec-introduction-to-bayesian-inference"></span><h1>Introduction to Bayesian Inference<a class="headerlink" href="#introduction-to-bayesian-inference" title="Permalink to this headline">¶</a></h1>
<p>In this section, I want to illustrate some basic ideas of “classification.” It will help us to understand some of the notation and some of the general concepts used throughout this document. It will illustrate the role of priors, the problem of classification in the context of imbalanced classes, and how to estimate classification performance correctly. Finally, it will also describe and provide some of the most important tools we will use for the data and statistical analysis.</p>
<div class="section" id="example-screening-for-autism-spectrum-disorder">
<span id="example-screening-for-asd-headturn"></span><h2>Example: Screening for Autism Spectrum Disorder<a class="headerlink" href="#example-screening-for-autism-spectrum-disorder" title="Permalink to this headline">¶</a></h2>
<p>Let us start with an example. Assume we have the task of determining whether a child has Autism Spectrum Disorder (ASD), and we have available, only one clinical measure “x.”</p>
<div class="admonition-notation admonition">
<p class="admonition-title">Notation</p>
<p>The universe of subjects/samples will be noted as <span class="math notranslate nohighlight">\(\mathcal{U}\)</span>, for each subject <span class="math notranslate nohighlight">\(s_i\in\mathcal{U}\)</span>, its ground truth label is represented by <span class="math notranslate nohighlight">\(y_i\)</span>, in this example we associate the value <span class="math notranslate nohighlight">\(y=1\)</span> with the ASD group (and <span class="math notranslate nohighlight">\(0\)</span> otherwise). The feature <span class="math notranslate nohighlight">\(X\)</span> is a measure we will use for classification/prediction, <span class="math notranslate nohighlight">\(x_i\)</span> represent the value of the feature for the subject <span class="math notranslate nohighlight">\(s_i\)</span>.</p>
</div>
<p>An example of feature is the delay on head-turning after a name call.<a class="bibtex reference internal" href="bibliography.html#campbell2019computer" id="id1">[CCH+19]</a> For example, given a subject <span class="math notranslate nohighlight">\(s_i\)</span>, we are provided with a value <span class="math notranslate nohighlight">\(x_i\)</span> that corresponds to the subjects’ delay in seconds after his/her name is called. Given this information, we want to infer what is the probability that the child has ASD or not (<span class="math notranslate nohighlight">\(y_i=1\)</span> or <span class="math notranslate nohighlight">\(y_i=0\)</span>). Let’s build a numerical example.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>All the number and experiments here presented are made up. This document focuses on the mathematical tools, and is not intended to present or analyze any real data nor extract real behavioral conclusion.</p>
</div>
<div class="cell tag_remove-output tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import pre-installed packages and init. </span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> 
<span class="kn">import</span> <span class="nn">os</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">sys</span> 
<span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>

<span class="c1"># add tools path and import our own tools</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;../tools&#39;</span><span class="p">)</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">14</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let us create some toy data:</span>
<span class="kn">from</span> <span class="nn">create_data</span> <span class="kn">import</span> <span class="n">create_headturn_toy_example</span>
<span class="n">X_u</span><span class="p">,</span> <span class="n">Y_u</span> <span class="o">=</span> <span class="n">create_headturn_toy_example</span><span class="p">(</span><span class="n">num_points</span><span class="o">=</span><span class="mf">1e5</span><span class="p">,</span> <span class="n">prop_positive</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">create_headturn_toy_example</span><span class="p">(</span><span class="n">num_points</span><span class="o">=</span><span class="mf">1e3</span><span class="p">,</span> <span class="n">prop_positive</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">X_u</span></code> and <code class="docutils literal notranslate"><span class="pre">Y_u</span></code> denote the set of <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> values for the subjects in our universe <span class="math notranslate nohighlight">\(\mathcal{U}\)</span>. We simulated that there are <span class="math notranslate nohighlight">\(10k\)</span> kids in our target population <span class="math notranslate nohighlight">\(\mathcal{U}\)</span>. On the other hand, <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">Y</span></code> represent a dataset we have available, i.e., the kids that came to the clinic. The main objective is to use our sample <span class="math notranslate nohighlight">\((X,Y)\)</span> to develop and evaluate tools that work on our target population with data <span class="math notranslate nohighlight">\((X_u,Y_u)\)</span>.</p>
<p><strong>The priors might vary between the target population and the set available.</strong> In this experiment, we model that 5% of the kids in <span class="math notranslate nohighlight">\(\mathcal{U}\)</span> have ASD. In our sample <span class="math notranslate nohighlight">\((X,Y)\)</span> on the other hand, we simulated a larger proportion of ASD children: 20%. This means that for the data we have available, we have four times more chances of sampling an ASD child if we select a child at random. Overrepresenting the minority class when empirical data is collected is a common and reasonable practice. We want to learn key features that represent both classes, and we need a considerable number of samples from both categories. Sampling at random from <span class="math notranslate nohighlight">\(\mathcal{U}\)</span> would be very inefficient in terms of getting samples from the minority class (since we are considering imbalanced problems). Instead, we can work with a set that over-represents the minority class and correct the metrics, so the performance matches the prior in the actual population, as we discuss in the following. ADDREF</p>
</div>
<div class="section" id="identifying-and-assessing-descriptive-features">
<h2>Identifying and assessing descriptive features.<a class="headerlink" href="#identifying-and-assessing-descriptive-features" title="Permalink to this headline">¶</a></h2>
<p>Let’s start to look into the data and try to get some idea about the following questions: <strong>Q1: Is the head turn delay a useful feature for the diagnosis of ASD? If the answer is “Yes,” Q2: how reliable this biomarker is?</strong></p>
<p>To answer the previous questions, we can start by looking at the data we have available <span class="math notranslate nohighlight">\((X,Y)\)</span>:</p>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute and plot the histogram of X values for each clas. </span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">,</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span><span class="n">Y</span><span class="p">});</span> 
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;Y==0&#39;</span><span class="p">)[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span> 
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;Y==1&#39;</span><span class="p">)[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Head turn delay in seconds (X)&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">]);</span>

<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;hist_head_turn_lab&quot;</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-default" id="fig-hist-head-turn-lab" style="width: 50%">
<div class="cell_output docutils container">
<img alt="../_images/bayes_5_0.png" src="../_images/bayes_5_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text">Distribution of the head turn values on the sample data (X,Y). The blue and orange distributions represent the histogram across the non-ASD and ASD groups respectively, (P(X|Y)).</span><a class="headerlink" href="#fig-hist-head-turn-lab" title="Permalink to this image">¶</a></p>
</div>
<p>Looking at the results of <a class="reference internal" href="#fig-hist-head-turn-lab"><span class="std std-numref">Fig. 1</span></a>, the answer to Q1 seems to be YES! Head-turn delay looks like a descriptive biomarker for autism (recall this is just simulated data and a toy example). For the moment, we are answering the question informally, just by looking at the blue and orange distributions and observing that <em>they look different</em>. Of course a more formal statistical approach can be adopted, which is the subject of Section <a class="reference internal" href="hypothesisTesting.html#sec-hypothesis-testing"><span class="std std-ref">Hypothesis testing and effect size</span></a>.</p>
<p>This toy data suggests that kids in the non-ASD group are turning their heads faster after a name call. It also looks that if the delay is below one second, we are almost certain the kid belongs to the non-ASD group. At the same time, for values larger than 2s, there is a higher chance for the kid to be on the ASD group. Finally, if <span class="math notranslate nohighlight">\(x_i\approx 2\)</span> we do not have much information about whether the subject <span class="math notranslate nohighlight">\(s_i\)</span> is in one group or the other. According to these observations, answering Q2:how accurate is this feature? Is not trivial, the first answer seems to be: “it depends where in this distributions you fall.” We will address this formally in section <a class="reference internal" href="#subsec-posterior-odds"><span class="std std-ref">Posterior odds</span></a>.</p>
</div>
<div class="section" id="the-importance-of-priors-on-imbalance-problems">
<h2>The importance of priors on imbalance problems<a class="headerlink" href="#the-importance-of-priors-on-imbalance-problems" title="Permalink to this headline">¶</a></h2>
<p>The distributions shown in <a class="reference internal" href="#fig-hist-head-turn-lab"><span class="std std-numref">Fig. 1</span></a> can be miss-leading, since they only illustrate the distribution of the feature (<span class="math notranslate nohighlight">\(X\)</span>) withing the classes (i.e., <span class="math notranslate nohighlight">\(P(X|y=0)\)</span> and <span class="math notranslate nohighlight">\(P(X|y=1)\)</span>), but they do not take into account that the occurrence of one of the classes is much more frequent than the other (i.e., <span class="math notranslate nohighlight">\(p(y=1) \ll p(y=0)\)</span>).
For example, one might wrongly conclude that if a child has a delay of 3 seconds on responding to the name call, then he/she has <em>more chances</em> of being in the ASD group compared to the non-ASD group. More precisely, what we need to estimate is the probability of <span class="math notranslate nohighlight">\(y=1\)</span> given that we observed <span class="math notranslate nohighlight">\(x=3s\)</span>, formally, <span class="math notranslate nohighlight">\(P(Y|X)\)</span> (not <span class="math notranslate nohighlight">\(P(X|Y)\)</span>!). We can achieve this using Bayes Theorem <a class="bibtex reference internal" href="bibliography.html#duda2012pattern" id="id2">[DHS12]</a> <a class="bibtex reference internal" href="bibliography.html#wasserman2013all" id="id3">[Was13]</a>:</p>
<div class="math notranslate nohighlight" id="equation-eq-bayes-theorem">
<span class="eqno">(1)<a class="headerlink" href="#equation-eq-bayes-theorem" title="Permalink to this equation">¶</a></span>\[
P(Y|X) = \frac{P(X|Y)P(Y)}{P(X)}.
\]</div>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;X&#39;</span><span class="p">:</span><span class="n">X_u</span><span class="p">,</span><span class="s1">&#39;Y&#39;</span><span class="p">:</span><span class="n">Y_u</span><span class="p">});</span> 
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;Y==0&#39;</span><span class="p">)[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">False</span><span class="p">);</span> 
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;Y==1&#39;</span><span class="p">)[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">False</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">]);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Head turn delay in seconds (X)&#39;</span><span class="p">);</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;hist_with_prior_head_turn_lab&quot;</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-default" id="fig-hist-with-prior-head-turn-lab" style="width: 50%">
<div class="cell_output docutils container">
<img alt="../_images/bayes_10_0.png" src="../_images/bayes_10_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text">Distribution of the head turn values on the sample data (X,Y) including the classes prior.
The blue and orange distributions represent the absolute number of samples for each X value withing the non-ASD and ASD groups: (P(X|Y)P(Y)).</span><a class="headerlink" href="#fig-hist-with-prior-head-turn-lab" title="Permalink to this image">¶</a></p>
</div>
<p><a class="reference internal" href="#fig-hist-with-prior-head-turn-lab"><span class="std std-numref">Fig. 2</span></a> shows the distributions <span class="math notranslate nohighlight">\(P(X|Y)P(Y)\)</span> which take into account the important prior factor <span class="math notranslate nohighlight">\(P(Y)\)</span>. Compare for example <a class="reference internal" href="#fig-hist-head-turn-lab"><span class="std std-numref">Fig. 1</span></a> and <a class="reference internal" href="#fig-hist-with-prior-head-turn-lab"><span class="std std-numref">Fig. 2</span></a>, and notice how even if a child presents a delay of 3 seconds in responding (<span class="math notranslate nohighlight">\(X=3s\)</span>) is still more likely that he/she is in the non-ASD group. Even though <span class="math notranslate nohighlight">\(P(X=3|y=1)&gt;P(X=3|y=0)\)</span>, we have that <span class="math notranslate nohighlight">\(P(X=3|y=1)P(y=1)&lt;P(X=3|y=0)P(y=0)\)</span>. A practical solution to properly asses risk factors, is to consider the <a class="reference internal" href="#subsec-posterior-odds"><span class="std std-ref">posterior probability odds</span></a>.</p>
</div>
<div class="section" id="posterior-odds">
<span id="subsec-posterior-odds"></span><h2>Posterior odds<a class="headerlink" href="#posterior-odds" title="Permalink to this headline">¶</a></h2>
<p>A significant imbalance between the frequency of the classes poses several challenges, in particular, on how to measure performance (we will discuss performance measures in Section <a class="reference internal" href="#subsec-performance-measures"><span class="std std-ref">Performance measures for imbalance problems</span></a>). To illustrate this issue, ASD has a prevalence under <span class="math notranslate nohighlight">\(5\%\)</span>, which means that if we always assume a child is TD, we will be right more than <span class="math notranslate nohighlight">\(95\%\)</span> of the time, though we are not helping a single child with ASD.</p>
<p>In the previous sections, we discussed the importance of priors and formalized ideas in the framework of Bayesian inference. It follows naturally that a way of assessing the likelihood of a class is to compare how much more likely is <span class="math notranslate nohighlight">\(Y=1\)</span> than <span class="math notranslate nohighlight">\(Y=0\)</span> given <span class="math notranslate nohighlight">\(X=x\)</span>. Formally,</p>
<div class="math notranslate nohighlight" id="equation-posteriorodds">
<span class="eqno">(2)<a class="headerlink" href="#equation-posteriorodds" title="Permalink to this equation">¶</a></span>\[
\frac{P(Y=1|X)}{P(Y=0|X)} = \frac{P(X|Y=1)P(Y=1)}{P(X|Y=0)P(Y=0)},
\]</div>
<p>where the equality follows from Bayes theorem.</p>
<p>For example, <span class="math notranslate nohighlight">\(\frac{P(Y=1|X)}{P(Y=0|X)}=2\)</span> means that given the value of X, the probability of the subject to be in the ASD group is twice the probability of being in the TD group. Notice that when “X” has no information about “Y” (i.e., we measure a useless feature)</p>
<div class="math notranslate nohighlight">
\[
\frac{P(Y=1|X)}{P(Y=0|X)} \rightarrow \frac{P(Y=1)}{P(Y=0)}.
\]</div>
<p>The term <span class="math notranslate nohighlight">\(P(Y|X)\)</span> is named as the posterior probability, and therefore the fraction <span class="math notranslate nohighlight">\(\frac{P(Y=1|X)}{P(Y=0|X)}\)</span> is referred to as the posterior odds. Though this quantity has an intuitive meaning (how many times more likely one class is than the other), it does not account for the imbalance between the classes. To incorporate this information, we can compare the posterior odds with the prior odds, using the latter as a form of normalization:</p>
<div class="math notranslate nohighlight" id="equation-posteriorodds-normalized">
<span class="eqno">(3)<a class="headerlink" href="#equation-posteriorodds-normalized" title="Permalink to this equation">¶</a></span>\[
\frac{\frac{P(Y=1|X)}{P(Y=0|X)}}{\frac{P(Y=1)}{P(Y=0)}} = \frac{P(X|Y=1)}{P(X|Y=0)}.
\]</div>
<p>Equation <a class="reference internal" href="#equation-posteriorodds-normalized">(3)</a> shows that the normalized posterior odds can be computed from the conditional distributions <span class="math notranslate nohighlight">\(P(X|Y)\)</span>, which has a very practical impact.</p>
<div class="cell tag_remove_output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stats</span> <span class="kn">import</span> <span class="n">feature_values_positive_to_negative_ratio</span>
<span class="n">Xp</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">Y</span><span class="o">==</span><span class="mi">1</span><span class="p">];</span> <span class="n">Xn</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">Y</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">]);</span> 
<span class="n">Q</span> <span class="o">=</span> <span class="n">feature_values_positive_to_negative_ratio</span><span class="p">(</span><span class="n">Xp</span><span class="o">=</span><span class="n">Xp</span><span class="p">,</span> <span class="n">Xn</span><span class="o">=</span><span class="n">Xn</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;posterior_odds_normalized&quot;</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-default" id="fig-posterior-odds-normalized" style="width: 100%">
<div class="cell_output docutils container">
<img alt="../_images/bayes_14_0.png" src="../_images/bayes_14_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 3 </span><span class="caption-text">Left: Distribution of the feature X for each class (P(X|Y)). Right: normalized posterior odds in logarithmic scale.</span><a class="headerlink" href="#fig-posterior-odds-normalized" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="performance-measures-for-imbalance-problems">
<span id="subsec-performance-measures"></span><h2>Performance measures for imbalance problems<a class="headerlink" href="#performance-measures-for-imbalance-problems" title="Permalink to this headline">¶</a></h2>
<p>Let assume after analysis, we decide we will predict ASD versus non-ASD labels depending on the kid’s head turn delay after a name call. For example, we can define <span class="math notranslate nohighlight">\(\hat{y} \stackrel{def}{=} x&gt;2\)</span>, this is, <span class="math notranslate nohighlight">\(\hat{y}=1\)</span> for all the kids which response is slower than two seconds, and <span class="math notranslate nohighlight">\(\hat{y} = 0\)</span> for all the kids which response is faster or equal than two seconds. Recall that for each participant we have their ground truth label <span class="math notranslate nohighlight">\(y=1\)</span> if they are in the ASD group, <span class="math notranslate nohighlight">\(y=0\)</span> if they are in the non-ASD group.</p>
<p>Four quantities fully describe the performance of a classification algorithm: number of true positive (TP), true negative (TN), false positive (FP), and false negative (FN). The TP is define as the number of subject for which <span class="math notranslate nohighlight">\(y=1\)</span> and <span class="math notranslate nohighlight">\(\hat{y}=1\)</span>, TN the number of subject for which <span class="math notranslate nohighlight">\(y=0\)</span> and <span class="math notranslate nohighlight">\(\hat{y}=0\)</span>, FP the number of subject for which <span class="math notranslate nohighlight">\(y=0\)</span> and <span class="math notranslate nohighlight">\(\hat{y}=1\)</span> and finally, FN the number of subjects for which <span class="math notranslate nohighlight">\(y=1\)</span> and <span class="math notranslate nohighlight">\(\hat{y}=0\)</span>.</p>
<p>Some useful metrics for the evaluation of classifiers are: Accuracy <span class="math notranslate nohighlight">\(\frac{TP+TN}{TP+TN+FP+FN}\)</span>, others? As we discussed earlier, measures such as the accuracy are not suited for imbalance problems. Instead, appropriate metrics are: recall <span class="math notranslate nohighlight">\(\frac{TP}{TP+FN}\)</span> (a.k.a sensitivity, true positive rate), precision <span class="math notranslate nohighlight">\(\frac{TP}{TP+FP}\)</span> (a.k.a. positive predictive value), f-value (which is a weighted average between recall and precision), true negative rate <span class="math notranslate nohighlight">\(\frac{TN}{TN+FP}\)</span>, or false positive rate <span class="math notranslate nohighlight">\(\frac{FP}{FP+TN}\)</span>. Another family of metrics provides information about a “family” of solutions rather than the performance on particular operation points. For example, the ROC curve shows the false positive rate (horizontal axis) versus the true positive rate (vertical axis). It is important to notice that the ROC curve does not provide the performance of a particular implementation. (There is no particular fixed labels nor fixed values for the TP, TN, FP, and FN). Instead, it shows a “family” of solutions when one hyper-parameter (typically a classification threshold) varies. To overcome this limitation, measures such as the area under the roc curve (AUC) have been proposed.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If the proportion of positive and negative samples in the dataset is different from the ratio in the entire population (which in general happens in the clinic), some of the measures listed above will be skewed. To have an accurate performance estimation, this issue should analyzed.</p>
</div>
<div class="section" id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h3>
<p>We discussed the role of priors, and why measuring “detection” in problems with imbalance classes is not trivial. We discussed how Bayes’s ideas provide a possible framework to formalize and explain these concepts. We showed that it is essential to add to the extracted features, confidence measures with a probabilist and interpretable meaning.</p>
<p>So far, we assumed we could approximate <span class="math notranslate nohighlight">\(P(X|Y)\)</span> by measuring the “histogram” of the observed values of <span class="math notranslate nohighlight">\(X\)</span> over an empirical sample. Section <a class="reference internal" href="pdfestimation.html#sec-pdf-estimation"><span class="std std-ref">Estimation of PDF and CDF distributions</span></a> formalizes this concept and discusses how to calculate the estimation error and confidence intervals.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "stats"
        },
        kernelOptions: {
            kernelName: "stats",
            path: "./sections"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'stats'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../index.html" title="previous page">Notes on statistical analysis and inference</a>
    <a class='right-next' id="next-link" href="pdfestimation.html" title="next page">Estimation of PDF and CDF distributions</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By J. Matias Di Martino<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>